{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataset.py\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.v2 as v2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class TextRecognitionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, phase, root='./data', tranform=None, preprocessing=None):\n",
    "\n",
    "        self.tranform = tranform\n",
    "        self.preprocessing =preprocessing\n",
    "        self.phase = phase\n",
    "\n",
    "        if phase == 'train':\n",
    "            self.image_path_simple = os.path.join(root, phase, phase, 'simple')\n",
    "            self.image_path_complex = os.path.join(root, phase, phase, 'complex')\n",
    "\n",
    "            self.simple = os.listdir(self.image_path_simple)\n",
    "            self.complex = os.listdir(self.image_path_complex)\n",
    "\n",
    "            self.all_images = self.simple + self.complex \n",
    "            self.image2label = {label: label.split('.')[0].split('_')[-1] for label in self.all_images}\n",
    "\n",
    "        elif phase == 'test':\n",
    "            self.image_path = os.path.join(root, phase, 'result')\n",
    "            self.all_images = os.listdir(self.image_path)\n",
    "            self.image2label = {label: label.split('.')[0].split('_')[-1] for label in self.all_images}\n",
    "            \n",
    "        else:\n",
    "            raise ValueError('Wrong name for phase: choose train or test')  \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image = self.all_images[index]\n",
    "        label = self.image2label[image]\n",
    "\n",
    "        if self.phase == 'train':\n",
    "\n",
    "            if image in self.simple:\n",
    "                image  = Image.open(os.path.join(self.image_path_simple, image))\n",
    "\n",
    "            else:\n",
    "                image  = Image.open(os.path.join(self.image_path_complex, image))\n",
    "\n",
    "        else:\n",
    "            image  = Image.open(os.path.join(self.image_path, image))\n",
    "\n",
    "        # make one channel (gray)\n",
    "        image = image.convert('L')\n",
    "\n",
    "\n",
    "        if self.preprocessing:\n",
    "            image = self.preprocessing(image)\n",
    "\n",
    "        if self.tranform:\n",
    "            image = self.tranform(image)\n",
    "\n",
    "        return image, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image2label)\n",
    "\n",
    "\n",
    "\n",
    "def ada_thr(img):\n",
    "    img = np.array(img)\n",
    "    ada_mean_thr = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2)\n",
    "    ada_gaus_thr = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    result = np.concatenate([img[:, :, None], ada_mean_thr[:, :, None], ada_gaus_thr[:, :, None]], axis=2)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "defualt_transform = v2.Compose([\n",
    "                        v2.Resize((32, 160)), \n",
    "                        v2.ToTensor(),\n",
    "                        v2.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "\n",
    "\n",
    "def get_dataloaders(BATCH_SIZE=16, preprcoessing=False, tranform=defualt_transform):\n",
    "    if preprcoessing:\n",
    "        preprocessing_fun = ada_thr\n",
    "    else:\n",
    "        preprocessing_fun = None\n",
    "\n",
    "    train_set = TextRecognitionDataset('train', preprocessing=preprocessing_fun, tranform=tranform)\n",
    "    test_set = TextRecognitionDataset('test', preprocessing=preprocessing_fun, tranform=tranform)\n",
    "\n",
    "    train = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "    test = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    train_dataloader, test_dataloader = get_dataloaders() \n",
    "    \n",
    "    for (image, label) in train_dataloader:\n",
    "        print('TRAIN')\n",
    "        print(label)\n",
    "        print(image.shape)\n",
    "        break\n",
    "    \n",
    "\n",
    "    for (image, _) in test_dataloader:\n",
    "        print('TEST')\n",
    "        print(image.shape)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
